{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webscrap.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgCE73ciWmjb"
      },
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "\n",
        "!pip install requests\n",
        "!pip install html5lib\n",
        "!pip install bs4\n",
        "\n",
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkkO71umsBAj"
      },
      "source": [
        "2018"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jahCmd1i3Fq5"
      },
      "source": [
        "# ## FOR A PROCEEDING\n",
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "# url = 'https://dl.acm.org/doi/proceedings/10.1145/3173574'\n",
        "# response = requests.get(url)\n",
        "# #full proceeding\n",
        "# soup = BeautifulSoup(response.content, features=\"lxml\")\n",
        "# sessions_secs = soup.find_all(\"div\", {\"class\": \"toc__section accordion-tabbed__tab\"}) # sessions closed\n",
        "# no_session_papers = soup.find_all(\"div\",{\"class\":\"issue-item-container\"})\n",
        "\n",
        "# paper_sessions=[]\n",
        "# for i in range(len(sessions_secs[:-1])):\n",
        "#   section_link = sessions_secs[i].find_all(\"a\",{\"class\":\"section__title accordion-tabbed__control left-bordered-title\"})[0].get('href')\n",
        "#   print(section_link)\n",
        "#   link = \"https://dl.acm.org\"+section_link #link to opening drop down\n",
        "#   response = requests.get(link)\n",
        "#   ## SESSION PAGE\n",
        "#   soup2 = BeautifulSoup(response.content, features=\"lxml\")\n",
        "#   opened_session_sec = soup2.find_all(\"div\",{\"class\":\"toc__section accordion-tabbed__tab\"})[i] \n",
        "#   paper_section = opened_session_sec.find_all(\"div\",{\"class\":\"issue-item-container\"}) \n",
        "#   papers=[]\n",
        "#   for k in range(len(paper_section)):\n",
        "#     title = paper_section[k].select(\"h5[class=issue-item__title]\")[0].select(\"a\")[0].contents[0]\n",
        "#     paper_link = 'https://dl.acm.org'+ paper_section[k].select(\"h5[class=issue-item__title]\")[0].select(\"a\")[0].get('href')\n",
        "#     wd = webdriver.Chrome('chromedriver',options=options)\n",
        "#     wd.get(paper_link)\n",
        "#     html = wd.page_source\n",
        "#     soup4 = BeautifulSoup(html, \"html.parser\") \n",
        "#     wd.close()\n",
        "\n",
        "#     paper_badges = soup4.find_all(\"span\",{\"class\":\"badges dot-separator\"})\n",
        "#     badge_0 = 0 # (not) best paper\n",
        "#     badge_1 = 0 # (not) honourable mention\n",
        "#     if (len(paper_badges)>0):\n",
        "#         badge = paper_badges[0].select(\"a\")[0].get(\"data-title\")\n",
        "#         if (badge==\"Best Paper\"):\n",
        "#           badge_1 = 1\n",
        "#         if (badge==\"Honorable Mention\"):\n",
        "#           badge_0 = 1\n",
        "\n",
        "#     auth_sec = soup4.find_all(\"div\",{\"class\":\"pill-all-authors authors-accordion disable-truncate hidden\"})[0]\n",
        "#     auths_info = auth_sec.find_all(\"li\",{\"class\":\"loa__item\"})\n",
        "#     auths=[]\n",
        "#     for ai in auths_info:\n",
        "#       name = ai.select(\"a[class=author-name]\")[0].get(\"title\")\n",
        "#       inst = ai.select(\"span[class=loa_author_inst]\")[0].select(\"p\")[0].contents[0]\n",
        "#       auths.append([name,inst])\n",
        "#     papers.append([badge_0, badge_1,title,auths])  \n",
        "#   paper_sessions.append(papers)\n",
        "\n",
        "\n",
        "# paper_section = no_session_papers\n",
        "# papers=[]\n",
        "# for k in range(len(paper_section)):\n",
        "#   title = paper_section[k].select(\"h5[class=issue-item__title]\")[0].select(\"a\")[0].contents[0]\n",
        "#   paper_link = 'https://dl.acm.org'+ paper_section[k].select(\"h5[class=issue-item__title]\")[0].select(\"a\")[0].get('href')\n",
        "#   wd = webdriver.Chrome('chromedriver',options=options)\n",
        "#   wd.get(paper_link)\n",
        "#   html = wd.page_source\n",
        "#   soup4 = BeautifulSoup(html, \"html.parser\") \n",
        "#   wd.close()\n",
        "\n",
        "#   paper_badges = soup4.find_all(\"span\",{\"class\":\"badges dot-separator\"})\n",
        "#   badge_0 = 0 # (not) best paper\n",
        "#   badge_1 = 0 # (not) honourable mention\n",
        "#   if (len(paper_badges)>0):\n",
        "#       badge = paper_badges[0].select(\"a\")[0].get(\"data-title\")\n",
        "#       if (badge==\"Best Paper\"):\n",
        "#         badge_1 = 1\n",
        "#       if (badge==\"Honorable Mention\"):\n",
        "#         badge_0 = 1\n",
        "#   auth_sec = soup4.find_all(\"div\",{\"class\":\"pill-all-authors authors-accordion disable-truncate hidden\"})[0]\n",
        "#   auths_info = auth_sec.find_all(\"li\",{\"class\":\"loa__item\"})\n",
        "#   auths=[]\n",
        "#   for ai in auths_info:\n",
        "#     name = ai.select(\"a[class=author-name]\")[0].get(\"title\")\n",
        "#     inst = ai.select(\"span[class=loa_author_inst]\")[0].select(\"p\")[0].contents[0]\n",
        "#     auths.append([name,inst])\n",
        "#   papers.append([badge_0, badge_1,title,auths])  \n",
        "# paper_sessions.append(papers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqsMGcNCiYk1"
      },
      "source": [
        "# import xlwt \n",
        "# from xlwt import Workbook \n",
        "# wb = Workbook() \n",
        "\n",
        "# sheet = wb.add_sheet(\"2018\") \n",
        "# sheet.write(0,1,'1 => Best Paper') \n",
        "# sheet.write(0, 0, '1 => Honorable Mention') \n",
        "# sheet.write(0, 2, 'Paper Name') \n",
        "# sheet.write(0, 3, 'Authors') \n",
        "# sheet.write(0, 4, 'Affiliation') \n",
        "# ind = 1\n",
        "\n",
        "# for i in range(len(paper_sessions)):\n",
        "#   for j in paper_sessions[i]:\n",
        "#     b0 = j[0]\n",
        "#     b1 = j[1]\n",
        "#     title = j[2]\n",
        "#     auths = j[3]\n",
        "#     sheet.write(ind,0,str(b0))\n",
        "#     sheet.write(ind,1,str(b1))\n",
        "#     sheet.write(ind,2,str(title))\n",
        "#     for a in auths:\n",
        "#       sheet.write(ind,3,a[0])\n",
        "#       sheet.write(ind,4,a[1])\n",
        "#       ind+=1\n",
        "\n",
        "# wb.save('proceed.xls')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOnoMEKcsH69"
      },
      "source": [
        "2015/2016/2017"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cXIKpimsK5r"
      },
      "source": [
        "# ## FOR A PROCEEDING\n",
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "# # url = 'https://dl.acm.org/doi/proceedings/10.1145/2702123' #2015\n",
        "# # url = 'https://dl.acm.org/doi/proceedings/10.1145/2858036' #2016\n",
        "# url = 'https://dl.acm.org/doi/proceedings/10.1145/3025453' #2017\n",
        "\n",
        "# response = requests.get(url)\n",
        "# #full proceeding\n",
        "# soup = BeautifulSoup(response.content, features=\"lxml\")\n",
        "# sessions_secs = soup.find_all(\"div\", {\"class\": \"toc__section accordion-tabbed__tab\"}) # sessions closed\n",
        "# no_session_papers = soup.find_all(\"div\",{\"class\":\"issue-item-container\"})\n",
        "\n",
        "# paper_sessions=[]\n",
        "# for i in range(len(sessions_secs[:-1])):\n",
        "#   section_link = sessions_secs[i].find_all(\"a\",{\"class\":\"section__title accordion-tabbed__control left-bordered-title\"})[0].get('href')\n",
        "#   print(section_link)\n",
        "#   link = \"https://dl.acm.org\"+section_link #link to opening drop down\n",
        "#   response = requests.get(link)\n",
        "#   ## SESSION PAGE\n",
        "#   soup2 = BeautifulSoup(response.content, features=\"lxml\")\n",
        "#   opened_session_sec = soup2.find_all(\"div\",{\"class\":\"toc__section accordion-tabbed__tab\"})[i] \n",
        "#   paper_section = opened_session_sec.find_all(\"div\",{\"class\":\"issue-item-container\"}) \n",
        "#   papers=[]\n",
        "#   for k in range(len(paper_section)):\n",
        "#     title = paper_section[k].select(\"h5[class=issue-item__title]\")[0].select(\"a\")[0].contents[0]\n",
        "#     paper_link = 'https://dl.acm.org'+ paper_section[k].select(\"h5[class=issue-item__title]\")[0].select(\"a\")[0].get('href')\n",
        "#     wd = webdriver.Chrome('chromedriver',options=options)\n",
        "#     wd.get(paper_link)\n",
        "#     html = wd.page_source\n",
        "#     soup4 = BeautifulSoup(html, \"html.parser\") \n",
        "#     wd.close()\n",
        "\n",
        "#     paper_badges = soup4.find_all(\"span\",{\"class\":\"badges dot-separator\"})\n",
        "#     badge_0 = 0 # (not) honourable mention\n",
        "#     badge_1 = 0 # (not) best paper\n",
        "#     if (len(paper_badges)>0):\n",
        "#         badge = paper_badges[0].select(\"a\")[0].get(\"data-title\")\n",
        "#         if (badge==\"Best Paper\"):\n",
        "#           badge_1 = 1\n",
        "#         if (badge==\"Honorable Mention\"):\n",
        "#           badge_0 = 1\n",
        "\n",
        "#     auth_sec = soup4.find_all(\"div\",{\"class\":\"pill-all-authors authors-accordion disable-truncate hidden\"})[0]\n",
        "#     auths_info = auth_sec.find_all(\"li\",{\"class\":\"loa__item\"})\n",
        "#     auths=[]\n",
        "#     for ai in auths_info:\n",
        "#       name = ai.select(\"a[class=author-name]\")[0].get(\"title\")\n",
        "#       inst = ai.select(\"span[class=loa_author_inst]\")[0].select(\"p\")[0].contents[0]\n",
        "#       auths.append([name,inst])\n",
        "#     papers.append([badge_0, badge_1,title,auths])  \n",
        "#   paper_sessions.append(papers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHCTFXDDZ1tX"
      },
      "source": [
        "Creating sheet for 2015/2016/2017/2018"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVDanBtVsPOI"
      },
      "source": [
        "# import xlwt \n",
        "# from xlwt import Workbook \n",
        "# wb = Workbook() \n",
        "\n",
        "# st = \"Sheet\"\n",
        "# sheet = wb.add_sheet(st) \n",
        "# sheet.write(0, 5,'1 => Best Paper') \n",
        "# sheet.write(0, 4, '1 => Honorable Mention') \n",
        "# sheet.write(0, 1, 'Paper Name') \n",
        "# sheet.write(0, 2, 'Authors') \n",
        "# sheet.write(0, 3, 'Affiliation') \n",
        "# sheet.write(0, 0, 'Index') \n",
        "# paper_ind=1\n",
        "# ind = 1 \n",
        "\n",
        "# for i in range(len(paper_sessions)):\n",
        "#   for j in paper_sessions[i]: #papers\n",
        "#     b0 = j[0] #hm\n",
        "#     b1 = j[1] #bp\n",
        "#     title = j[2]\n",
        "#     if (str(title)[:16]!=\"Session details:\"):\n",
        "#       auths = j[3]\n",
        "#       s = ind\n",
        "#       for a in auths:\n",
        "#         sheet.write(ind,2,a[0])\n",
        "#         sheet.write(ind,3,a[1])\n",
        "#         ind+=1\n",
        "#       sheet.write(s,4,str(b0))\n",
        "#       sheet.merge(s,ind-1,4,4)\n",
        "#       sheet.write(s,5,str(b1))\n",
        "#       sheet.merge(s, ind-1, 5, 5)\n",
        "#       sheet.write(s,1,str(title))\n",
        "#       sheet.merge(s, ind-1, 1, 1)\n",
        "#       sheet.write(s,0,paper_ind)\n",
        "#       sheet.merge(s, ind-1, 0, 0)\n",
        "#       paper_ind+=1\n",
        "\n",
        "# wb.save('proceed_2017.xls')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSR-0OTNZfWC"
      },
      "source": [
        "2019/2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHRFDA-3Ij7B"
      },
      "source": [
        "## FOR A PROCEEDING\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# url = 'https://dl.acm.org/doi/proceedings/10.1145/3290605' # 2019\n",
        "url = 'https://dl.acm.org/doi/proceedings/10.1145/3313831' # 2020\n",
        "\n",
        "if_next_page = 1\n",
        "papers=[]\n",
        "while(if_next_page):\n",
        "  wd = webdriver.Chrome('chromedriver',options=options)\n",
        "  wd.get(url)\n",
        "  html = wd.page_source\n",
        "  soup = BeautifulSoup(html, \"html.parser\") \n",
        "  wd.close()\n",
        "\n",
        "  if_next_page = 0\n",
        "  next_page_info = soup.find_all(\"div\",{\"class\":\"see_more\"})\n",
        "  if (len(next_page_info))>0:\n",
        "    if_next_page = 1\n",
        "    url = 'https://dl.acm.org'+next_page_info[0].find_all(\"a\")[0].get('href')\n",
        "  \n",
        "  paper_section = soup.find_all(\"div\",{\"class\":\"issue-item-container\"})\n",
        "\n",
        "  for k in range(len(paper_section)):\n",
        "    title = paper_section[k].select(\"h5[class=issue-item__title]\")[0].select(\"a\")[0].contents[0]\n",
        "    paper_link = 'https://dl.acm.org'+ paper_section[k].select(\"h5[class=issue-item__title]\")[0].select(\"a\")[0].get('href')\n",
        "    wd = webdriver.Chrome('chromedriver',options=options)\n",
        "    wd.get(paper_link)\n",
        "    html = wd.page_source\n",
        "    soup4 = BeautifulSoup(html, \"html.parser\") \n",
        "    wd.close()\n",
        "\n",
        "    paper_badges = soup4.find_all(\"span\",{\"class\":\"badges dot-separator\"})\n",
        "    badge_0 = 0 # (not) best paper\n",
        "    badge_1 = 0 # (not) honourable mention\n",
        "    if (len(paper_badges)>0):\n",
        "        badge = paper_badges[0].select(\"a\")[0].get(\"data-title\")\n",
        "        if (badge==\"Best Paper\"):\n",
        "          badge_1 = 1\n",
        "        if (badge==\"Honorable Mention\"):\n",
        "          badge_0 = 1\n",
        "    auth_sec = soup4.find_all(\"div\",{\"class\":\"pill-all-authors authors-accordion disable-truncate hidden\"})[0]\n",
        "    auths_info = auth_sec.find_all(\"li\",{\"class\":\"loa__item\"})\n",
        "    auths=[]\n",
        "    for ai in auths_info:\n",
        "      name = ai.select(\"a[class=author-name]\")[0].get(\"title\")\n",
        "      inst = ai.select(\"span[class=loa_author_inst]\")[0].select(\"p\")[0].contents[0]\n",
        "      auths.append([name,inst])\n",
        "    papers.append([badge_0, badge_1,title,auths])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne1cYN5DZx-L"
      },
      "source": [
        "Creating sheet for 2019/2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaZELqp3VOGb"
      },
      "source": [
        "import xlwt \n",
        "from xlwt import Workbook \n",
        "wb = Workbook() \n",
        "\n",
        "st = \"Sheet\"\n",
        "sheet = wb.add_sheet(st) \n",
        "sheet.write(0, 5,'1 => Best Paper') \n",
        "sheet.write(0, 4, '1 => Honorable Mention') \n",
        "sheet.write(0, 1, 'Paper Name') \n",
        "sheet.write(0, 2, 'Authors') \n",
        "sheet.write(0, 3, 'Affiliation') \n",
        "sheet.write(0, 0, 'Index') \n",
        "paper_ind=1\n",
        "ind = 1 \n",
        "\n",
        "for i in range(len(papers)):\n",
        "  j = papers[i]\n",
        "  b0 = j[0] #honourable mention\n",
        "  b1 = j[1] #best paper\n",
        "  title = j[2]\n",
        "  if (str(title)[:16]!=\"Session details:\"):\n",
        "    auths = j[3]\n",
        "    s = ind\n",
        "    for a in auths:\n",
        "      sheet.write(ind,2,a[0])\n",
        "      sheet.write(ind,3,a[1])\n",
        "      ind+=1\n",
        "    sheet.write(s,4,str(b0))\n",
        "    sheet.merge(s,ind-1,4,4)\n",
        "    sheet.write(s,5,str(b1))\n",
        "    sheet.merge(s, ind-1, 5, 5)\n",
        "    sheet.write(s,1,str(title))\n",
        "    sheet.merge(s, ind-1, 1, 1)\n",
        "    sheet.write(s,0,paper_ind)\n",
        "    sheet.merge(s, ind-1, 0, 0)\n",
        "    paper_ind+=1\n",
        "\n",
        "wb.save('proceed_2020.xls')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}